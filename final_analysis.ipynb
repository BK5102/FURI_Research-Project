{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "selected_features_labeled  = pd.read_csv(\"selected_features.csv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values:  0\n",
      "Missing values per column: \n",
      " SEQN        0\n",
      "BPQ020      0\n",
      "DIQ010      0\n",
      "DID040      0\n",
      "DIQ220      0\n",
      "DIQ190A     0\n",
      "DIQ190B     0\n",
      "DIQ230      0\n",
      "DID260      0\n",
      "DIQ280      0\n",
      "DIQ300S     0\n",
      "DIQ300D     0\n",
      "PAQ180      0\n",
      "PADACTIV    0\n",
      "PADDURAT    0\n",
      "SLD010H     0\n",
      "LBXAPB      0\n",
      "LBDINSI     0\n",
      "LBXGH       0\n",
      "RIAGENDR    0\n",
      "RIDAGEMN    0\n",
      "dtype: int64\n",
      "Columns with all zero values:  SEQN           0\n",
      "BPQ020         0\n",
      "DIQ010         0\n",
      "DID040      4733\n",
      "DIQ220      4914\n",
      "DIQ190A        0\n",
      "DIQ190B        0\n",
      "DIQ230      4733\n",
      "DID260      4765\n",
      "DIQ280      4785\n",
      "DIQ300S     4733\n",
      "DIQ300D     4733\n",
      "PAQ180         0\n",
      "PADACTIV       0\n",
      "PADDURAT       3\n",
      "SLD010H        0\n",
      "LBXAPB       349\n",
      "LBDINSI      372\n",
      "LBXGH        329\n",
      "RIAGENDR       0\n",
      "RIDAGEMN      32\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "\n",
    "selected_features_labeled.value_counts()\n",
    "#zero_value_cols = selected_features_labeled.columns[(selected_features_labeled == 0).all()]\n",
    "#zero_only_cols = selected_features_labeled.columns[(selected_features_labeled.eq(0)).all()]\n",
    "zero_counts = (selected_features_labeled == 0).sum()\n",
    "\n",
    "print(\"Total missing values: \", selected_features_labeled.isnull().sum().sum())\n",
    "print(\"Missing values per column: \\n\", selected_features_labeled.isnull().sum())\n",
    "print(\"Columns with all zero values: \", zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros in the selected features: SEQN           0\n",
      "BPQ020         0\n",
      "DIQ010         0\n",
      "DID040      4733\n",
      "DIQ220      4914\n",
      "DIQ190A        0\n",
      "DIQ190B        0\n",
      "DIQ230      4733\n",
      "DID260      4765\n",
      "DIQ280      4785\n",
      "DIQ300S     4733\n",
      "DIQ300D     4733\n",
      "PAQ180         0\n",
      "PADACTIV       0\n",
      "PADDURAT       3\n",
      "SLD010H        0\n",
      "LBXAPB       349\n",
      "LBDINSI      372\n",
      "LBXGH        329\n",
      "RIAGENDR       0\n",
      "RIDAGEMN      32\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "zero_counts = (selected_features_labeled == 0).sum()\n",
    "print(\"Number of zeros in the selected features:\", zero_counts)\n",
    "\n",
    "#drop columns\n",
    "selected_features_labeled = selected_features_labeled.drop(columns=[\n",
    "    'DID040', 'DIQ220', 'DIQ230', 'DID260', 'DIQ280', 'DIQ300S', 'DIQ300D'\n",
    "], errors='ignore')\n",
    "\n",
    "cols_to_check = ['LBXAPB', 'LBDINSI', 'LBXGH', 'PADDURAT', 'RIDAGEMN']\n",
    "\n",
    "# Drop rows where any of the specified columns contain a zero\n",
    "selected_features_labeled = selected_features_labeled[(selected_features_labeled[cols_to_check] != 0).all(axis=1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_features_labeled\n",
    "\n",
    "## save cleaned data to a CSV file\n",
    "def save_cleaned_data(df, data_path=\"selected_features_final.csv\"):\n",
    "    if not df.empty:\n",
    "        df.to_csv(data_path, sep='\\t', index=False)\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "save_cleaned_data(selected_features_labeled, data_path=\"selected_features_final.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preDM filter\n",
    "def main():\n",
    "    combined_selected_features = pd.read_csv('selected_features_final.csv', sep='\\t')\n",
    "    preDM_criteria = (combined_selected_features['LBDINSI'] >= 100) | (combined_selected_features['LBXAPB'] >= 110) | (combined_selected_features['LBXGH'] >= 5.5)\n",
    "\n",
    "    combined_selected_features = preDMCondFilter(combined_selected_features, preDM_criteria)\n",
    "    return combined_selected_features\n",
    "\n",
    "def preDMCondFilter(combined_selected_features, preDM_criteria):\n",
    "    \n",
    "    #combined_selected_features.columns = combined_selected_features.columns.str.strip()\n",
    "\n",
    "    combined_selected_features['PreDM'] = preDM_criteria.astype(int)\n",
    "\n",
    "    combined_selected_features = combined_selected_features.drop(columns=['LBDINSI', 'LBXAPB', 'LBXGH'], errors='ignore')    \n",
    "\n",
    "    combined_selected_features.to_csv('selected_features_labeled_final.csv', sep='\\t', index=False)\n",
    "\n",
    "    return combined_selected_features\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>BPQ020</th>\n",
       "      <th>DIQ010</th>\n",
       "      <th>DIQ190A</th>\n",
       "      <th>DIQ190B</th>\n",
       "      <th>PAQ180</th>\n",
       "      <th>PADACTIV</th>\n",
       "      <th>PADDURAT</th>\n",
       "      <th>SLD010H</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEMN</th>\n",
       "      <th>PreDM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31148.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31150.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>43.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4531</th>\n",
       "      <td>41462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>41462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4533</th>\n",
       "      <td>41462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>41465.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535</th>\n",
       "      <td>41472.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4536 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SEQN  BPQ020  DIQ010  DIQ190A  DIQ190B  PAQ180  PADACTIV  PADDURAT  \\\n",
       "0     31132.0     1.0     1.0      1.0        1       2      42.0      40.0   \n",
       "1     31132.0     1.0     1.0      1.0        1       2      19.0     240.0   \n",
       "2     31134.0     1.0     2.0      1.0        1       3      42.0      30.0   \n",
       "3     31148.0     2.0     2.0      2.0        2       2      23.0      60.0   \n",
       "4     31150.0     2.0     2.0      2.0        2       4      43.0      60.0   \n",
       "...       ...     ...     ...      ...      ...     ...       ...       ...   \n",
       "4531  41462.0     2.0     2.0      2.0        2       3      42.0      30.0   \n",
       "4532  41462.0     2.0     2.0      2.0        2       3      20.0     120.0   \n",
       "4533  41462.0     2.0     2.0      2.0        2       3      29.0      10.0   \n",
       "4534  41465.0     2.0     2.0      1.0        1       1      42.0      30.0   \n",
       "4535  41472.0     1.0     2.0      2.0        1       2      29.0      20.0   \n",
       "\n",
       "      SLD010H  RIAGENDR  RIDAGEMN  PreDM  \n",
       "0         7.0       1.0       842      1  \n",
       "1         7.0       1.0       842      1  \n",
       "2         7.0       1.0       882      1  \n",
       "3         7.0       2.0       194      0  \n",
       "4         8.0       1.0       959      0  \n",
       "...       ...       ...       ...    ...  \n",
       "4531      8.0       1.0       678      0  \n",
       "4532      8.0       1.0       678      0  \n",
       "4533      8.0       1.0       678      0  \n",
       "4534      6.0       2.0       222      1  \n",
       "4535      8.0       1.0       410      0  \n",
       "\n",
       "[4536 rows x 12 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## models, common (prepare for model)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "#from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "#import matplotlib as plt\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "def prepareData():\n",
    "    labeled_selected_features = pd.read_csv('selected_features_labeled_final.csv', sep='\\t', header=0)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = encode_and_split(labeled_selected_features)\n",
    "\n",
    "    X_train_scaled, X_test_scaled = scaleFeatures(X_train, X_test)\n",
    " \n",
    "    #X_resampled, y_resampled = handle_class_imbalance(X_train_scaled, y_train)\n",
    "\n",
    "    return X_train_scaled, y_train, X_test_scaled, y_test, y_train\n",
    "\n",
    "def encode_and_split(labeled_selected_features):\n",
    "\n",
    "    #X = labeled_selected_features[['BPQ020', 'PADDURAT', 'SLD010H', 'RIAGENDR', 'LBXAPB', 'LBDINSI', 'LBXGH']]\n",
    "    X = labeled_selected_features[['BPQ020', 'DIQ010','DIQ190A','DIQ190B', 'PAQ180', 'PADACTIV', 'PADDURAT', 'SLD010H', 'RIAGENDR', 'RIDAGEMN']]\n",
    "    Y = labeled_selected_features[\"PreDM\"].copy()\n",
    "   \n",
    "    X = X.loc[Y.index]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, train_size=0.7, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def scaleFeatures(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# oversample the minority class using SMOTE\n",
    "# avoid overfitting\n",
    "# improves performance on imbalanced datasets\n",
    "\n",
    "\"\"\" def handle_class_imbalance(X_train_scaled, y_train):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    return X_resampled, y_resampled \"\"\"\n",
    "\n",
    "## decision tree and logistic regression\n",
    "def main():\n",
    "    X_train_scaled, X_test, X_test_scaled, y_test, y_train = prepareData()\n",
    "    #X_train_scaled, y_train, X_test_scaled, y_test, y_train\n",
    "    dt_accuracy = train_evaluate_model(X_train_scaled, X_test, X_test_scaled, y_test)\n",
    "    lr_accuracy = train_evaluate_model(X_train_scaled, X_test, X_test_scaled, y_test)\n",
    "    xgb_boost_accuracy = train_evaluate_model(X_train_scaled, X_test, X_test_scaled, y_test)\n",
    "    cross_validate(X_train_scaled, y_train)\n",
    "\n",
    "    return dt_accuracy, lr_accuracy, xgb_boost_accuracy\n",
    "\n",
    "def train_evaluate_model(X_train_scaled, X_test, X_test_scaled, y_test):\n",
    "\n",
    "    #decision tree\n",
    "    dt_model = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model.fit(X_train_scaled, X_test)\n",
    "\n",
    "    y_pred_dt = dt_model.predict(X_test_scaled)\n",
    "    accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "    print(f\"Decision Tree Accuracy: {accuracy_dt:.2f}\")\n",
    "    print(classification_report(y_test, y_pred_dt))\n",
    "    \n",
    "\n",
    "    #logistic regression\n",
    "    log_reg = LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)\n",
    "    log_reg.fit(X_train_scaled, X_test)\n",
    "\n",
    "    y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
    "\n",
    "    accuracy_log = accuracy_score(y_test, y_pred_log_reg)\n",
    "    print(f\"Logistic Regression Accuracy: {accuracy_log:.2f}\")\n",
    "    print(classification_report(y_test, y_pred_log_reg))\n",
    "\n",
    "    #XGBoost\n",
    "    xgb_model = xgb.XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "    xgb_model.fit(X_train_scaled, X_test, verbose=False) #prevent excessive text output\n",
    "\n",
    "    y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "    accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    print(f\"XGBoost Accuracy: {accuracy_xgb:.2f}\")\n",
    "    print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "    return accuracy_dt, accuracy_log, accuracy_xgb, y_test, y_pred_dt, y_pred_log_reg, y_pred_xgb\n",
    "\n",
    "## cross validation\n",
    "def cross_validate(X_train_scaled, y_train):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # Decision Tree Cross-Validation\n",
    "    dt_scores = cross_val_score(DecisionTreeClassifier(random_state=42), X_train_scaled, y_train, cv=kf, scoring='f1')\n",
    "    print(f\"Decision Tree Cross-Validation Scores: {dt_scores}\")\n",
    "    print(f\"Decision Tree Mean CV Accuracy: {dt_scores.mean():.2f}\")\n",
    "\n",
    "    # Logistic Regression Cross-Validation\n",
    "    lr_scores = cross_val_score(LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42), X_train_scaled, y_train, cv=kf, scoring='f1')\n",
    "    print(f\"Logistic Regression Cross-Validation Scores: {lr_scores}\")\n",
    "    print(f\"Logistic Regression Mean CV Accuracy: {lr_scores.mean():.2f}\")\n",
    "\n",
    "    # XGBoost Cross-Validation\n",
    "    xgb_scores = cross_val_score(xgb.XGBClassifier(eval_metric='logloss', random_state=42,alpha=0.5), X_train_scaled, y_train, cv=kf, scoring='f1')\n",
    "    print(f\"XGBoost Cross-Validation Scores: {xgb_scores}\")\n",
    "    print(f\"XGBoost Mean CV Accuracy: {xgb_scores.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       427\n",
      "           1       0.83      0.84      0.84       481\n",
      "\n",
      "    accuracy                           0.83       908\n",
      "   macro avg       0.83      0.83      0.83       908\n",
      "weighted avg       0.83      0.83      0.83       908\n",
      "\n",
      "Logistic Regression Accuracy: 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.68       427\n",
      "           1       0.73      0.61      0.66       481\n",
      "\n",
      "    accuracy                           0.67       908\n",
      "   macro avg       0.68      0.68      0.67       908\n",
      "weighted avg       0.68      0.67      0.67       908\n",
      "\n",
      "XGBoost Accuracy: 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80       427\n",
      "           1       0.82      0.81      0.82       481\n",
      "\n",
      "    accuracy                           0.81       908\n",
      "   macro avg       0.81      0.81      0.81       908\n",
      "weighted avg       0.81      0.81      0.81       908\n",
      "\n",
      "Decision Tree Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       427\n",
      "           1       0.83      0.84      0.84       481\n",
      "\n",
      "    accuracy                           0.83       908\n",
      "   macro avg       0.83      0.83      0.83       908\n",
      "weighted avg       0.83      0.83      0.83       908\n",
      "\n",
      "Logistic Regression Accuracy: 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.68       427\n",
      "           1       0.73      0.61      0.66       481\n",
      "\n",
      "    accuracy                           0.67       908\n",
      "   macro avg       0.68      0.68      0.67       908\n",
      "weighted avg       0.68      0.67      0.67       908\n",
      "\n",
      "XGBoost Accuracy: 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80       427\n",
      "           1       0.82      0.81      0.82       481\n",
      "\n",
      "    accuracy                           0.81       908\n",
      "   macro avg       0.81      0.81      0.81       908\n",
      "weighted avg       0.81      0.81      0.81       908\n",
      "\n",
      "Decision Tree Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       427\n",
      "           1       0.83      0.84      0.84       481\n",
      "\n",
      "    accuracy                           0.83       908\n",
      "   macro avg       0.83      0.83      0.83       908\n",
      "weighted avg       0.83      0.83      0.83       908\n",
      "\n",
      "Logistic Regression Accuracy: 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.68       427\n",
      "           1       0.73      0.61      0.66       481\n",
      "\n",
      "    accuracy                           0.67       908\n",
      "   macro avg       0.68      0.68      0.67       908\n",
      "weighted avg       0.68      0.67      0.67       908\n",
      "\n",
      "XGBoost Accuracy: 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80       427\n",
      "           1       0.82      0.81      0.82       481\n",
      "\n",
      "    accuracy                           0.81       908\n",
      "   macro avg       0.81      0.81      0.81       908\n",
      "weighted avg       0.81      0.81      0.81       908\n",
      "\n",
      "Decision Tree Cross-Validation Scores: [0.81967213 0.73650794 0.77622378 0.77181208 0.74916388 0.77742947\n",
      " 0.82649842 0.82131661 0.7797619  0.8       ]\n",
      "Decision Tree Mean CV Accuracy: 0.79\n",
      "Logistic Regression Cross-Validation Scores: [0.62068966 0.63945578 0.60215054 0.63380282 0.66220736 0.61889251\n",
      " 0.63636364 0.60869565 0.62706271 0.60992908]\n",
      "Logistic Regression Mean CV Accuracy: 0.63\n",
      "XGBoost Cross-Validation Scores: [0.80511182 0.80124224 0.78169014 0.77852349 0.81188119 0.7672956\n",
      " 0.82051282 0.80511182 0.8        0.8164557 ]\n",
      "XGBoost Mean CV Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "## display decision tree classification report \n",
    "dt_accuracy, lr_accuracy, xgb_accuracy = main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     41\u001b[39m     plt.show()\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[43mcontinous_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mcontinous_main\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontinous_main\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     X_train_scaled, X_test, X_test_scaled, y_test= prepareData()\n\u001b[32m      9\u001b[39m     labeled_selected_features = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mselected_features_labeled_final.csv\u001b[39m\u001b[33m'\u001b[39m, sep=\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m     y_test, y_pred_dt, y_pred_log_reg, y_pred_xgb = train_evaluate_model(X_train_scaled, X_test, X_test_scaled, y_test)\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "## visualization: pairplot of continous variables and confusion matrix of each model\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def continous_main():\n",
    "    X_train_scaled, X_test, X_test_scaled, y_test, y_train = prepareData()\n",
    "    labeled_selected_features = pd.read_csv('selected_features_labeled_final.csv', sep='\\t')\n",
    "    accuracy_dt, accuracy_log, accuracy_xgb, y_test, y_pred_dt, y_pred_log_reg, y_pred_xgb = train_evaluate_model(X_train_scaled, X_test, X_test_scaled, y_test)\n",
    "    \n",
    "    generate_confusion_matrix(y_test, y_pred_dt, \"Decision Tree Confusion Matrix\")\n",
    "    generate_confusion_matrix(y_test, y_pred_log_reg, \"Logistic Regression Confusion Matrix\")\n",
    "    generate_confusion_matrix(y_test, y_pred_xgb, \"XGBoost Confusion Matrix\")\n",
    "\n",
    "    continous_graph(labeled_selected_features)\n",
    "\n",
    "def continous_graph(labeled_selected_features):\n",
    "    continuous_vars = [col for col in labeled_selected_features.columns \n",
    "                       if labeled_selected_features[col].dtype in ['float64', 'int64']]\n",
    "    #remove SEQN value\n",
    "    del continuous_vars[0]\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "\n",
    "    sns.pairplot(labeled_selected_features, vars=continuous_vars, hue='PreDM', diag_kind='kde')\n",
    "    plt.title(\"Pairplot of all continous variables in dataset\", fontsize=10)\n",
    "    #print(\"test line\")\n",
    "    plt.savefig(\"final_visualizations/pairplot_before_division.png\") \n",
    "                        # before division of correct/wrong groups, confusion matrix\n",
    "    plt.show()\n",
    "\n",
    "def generate_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No PreDM', 'PreDM'], yticklabels=['No PreDM', 'PreDM'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(title)\n",
    "    plt.savefig(f\"final_visualizations/{title.replace(' ', '_').lower()}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    continous_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
