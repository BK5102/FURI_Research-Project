{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Data\n",
    "selected_features_labeled = pd.read_csv(\"selected_features.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values:  0\n",
      "Missing values per column:\n",
      " SEQN        0\n",
      "BPQ020      0\n",
      "DIQ010      0\n",
      "DIQ190A     0\n",
      "DIQ190B     0\n",
      "PAQ180      0\n",
      "PADACTIV    0\n",
      "PADDURAT    0\n",
      "SLD010H     0\n",
      "LBXAPB      0\n",
      "LBDINSI     0\n",
      "LBXGH       0\n",
      "RIAGENDR    0\n",
      "RIDAGEMN    0\n",
      "dtype: int64\n",
      "Columns with all zero values:\n",
      " SEQN        0\n",
      "BPQ020      0\n",
      "DIQ010      0\n",
      "DIQ190A     0\n",
      "DIQ190B     0\n",
      "PAQ180      0\n",
      "PADACTIV    0\n",
      "PADDURAT    0\n",
      "SLD010H     0\n",
      "LBXAPB      0\n",
      "LBDINSI     0\n",
      "LBXGH       0\n",
      "RIAGENDR    0\n",
      "RIDAGEMN    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## data cleaning\n",
    "\n",
    "# Check for missing values and zero-value columns\n",
    "zero_counts = (selected_features_labeled == 0).sum()\n",
    "print(\"Total missing values: \", selected_features_labeled.isnull().sum().sum())\n",
    "print(\"Missing values per column:\\n\", selected_features_labeled.isnull().sum())\n",
    "print(\"Columns with all zero values:\\n\", zero_counts)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "selected_features_labeled = selected_features_labeled.drop(columns=['DID040', 'DIQ220', 'DIQ230', 'DID260', 'DIQ280', 'DIQ300S', 'DIQ300D'], errors='ignore')\n",
    "\n",
    "# Drop rows where certain columns contain zeros\n",
    "cols_to_check = ['LBXAPB', 'LBDINSI', 'LBXGH', 'PADDURAT', 'RIDAGEMN']\n",
    "selected_features_labeled = selected_features_labeled[(selected_features_labeled[cols_to_check] != 0).all(axis=1)]\n",
    "\n",
    "# Save cleaned data\n",
    "selected_features_labeled.to_csv(\"selected_features_final.csv\", sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preDM filter\n",
    "\n",
    "# Reload cleaned dataset\n",
    "combined_selected_features = pd.read_csv(\"selected_features_final.csv\", sep='\\t')\n",
    "\n",
    "# Define PreDM condition\n",
    "preDM_criteria = (combined_selected_features['LBDINSI'] >= 100) | (combined_selected_features['LBXAPB'] >= 110) | (combined_selected_features['LBXGH'] >= 5.5)\n",
    "\n",
    "# Add 'PreDM' label\n",
    "combined_selected_features['PreDM'] = preDM_criteria.astype(int)\n",
    "\n",
    "# Drop features used for labeling\n",
    "combined_selected_features = combined_selected_features.drop(columns=['LBDINSI', 'LBXAPB', 'LBXGH'], errors='ignore')\n",
    "\n",
    "# Save final labeled dataset\n",
    "combined_selected_features.to_csv(\"selected_features_labeled_final.csv\", sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for analysis, train/test\n",
    "# Load labeled dataset\n",
    "labeled_selected_features = pd.read_csv(\"selected_features_labeled_final.csv\", sep='\\t')\n",
    "\n",
    "# Define features and target\n",
    "X = labeled_selected_features[['BPQ020', 'DIQ010', 'DIQ190A', 'DIQ190B', 'PAQ180', 'PADACTIV', 'PADDURAT', 'SLD010H', 'RIAGENDR', 'RIDAGEMN']]\n",
    "y = labeled_selected_features[\"PreDM\"]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.7, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.83\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       427\n",
      "           1       0.83      0.84      0.84       481\n",
      "\n",
      "    accuracy                           0.83       908\n",
      "   macro avg       0.83      0.83      0.83       908\n",
      "weighted avg       0.83      0.83      0.83       908\n",
      "\n",
      "Logistic Regression Accuracy: 0.67\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.68       427\n",
      "           1       0.73      0.61      0.66       481\n",
      "\n",
      "    accuracy                           0.67       908\n",
      "   macro avg       0.68      0.68      0.67       908\n",
      "weighted avg       0.68      0.67      0.67       908\n",
      "\n",
      "XGBoost Accuracy: 0.81\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80       427\n",
      "           1       0.82      0.81      0.82       481\n",
      "\n",
      "    accuracy                           0.81       908\n",
      "   macro avg       0.81      0.81      0.81       908\n",
      "weighted avg       0.81      0.81      0.81       908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## train/evaluate model\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test_scaled)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree Accuracy: {accuracy_dt:.2f}\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_log:.2f}\\n\", classification_report(y_test, y_pred_log_reg))\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train_scaled, y_train, verbose=False)\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb:.2f}\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Mean CV Accuracy: 0.77\n",
      "Logistic Regression Mean CV Accuracy: 0.63\n",
      "XGBoost Mean CV Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "## cross-validation of models\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Decision Tree CV\n",
    "dt_scores = cross_val_score(DecisionTreeClassifier(random_state=42), X_train_scaled, y_train, cv=kf, scoring='f1')\n",
    "print(f\"Decision Tree Mean CV Accuracy: {dt_scores.mean():.2f}\")\n",
    "\n",
    "# Logistic Regression CV\n",
    "lr_scores = cross_val_score(LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42), X_train_scaled, y_train, cv=kf, scoring='f1')\n",
    "print(f\"Logistic Regression Mean CV Accuracy: {lr_scores.mean():.2f}\")\n",
    "\n",
    "# XGBoost CV\n",
    "xgb_scores = cross_val_score(xgb.XGBClassifier(eval_metric='logloss', random_state=42, alpha=0.5), X_train_scaled, y_train, cv=kf, scoring='f1')\n",
    "print(f\"XGBoost Mean CV Accuracy: {xgb_scores.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1: \n",
      "[[352  75]\n",
      " [ 96 385]]\n",
      "\n",
      "Confusion Matrix for Fold 2: \n",
      "[[386  68]\n",
      " [ 76 377]]\n",
      "\n",
      "Confusion Matrix for Fold 3: \n",
      "[[396  80]\n",
      " [ 90 341]]\n",
      "\n",
      "Confusion Matrix for Fold 4: \n",
      "[[360  80]\n",
      " [ 89 378]]\n",
      "\n",
      "Confusion Matrix for Fold 5: \n",
      "[[390  80]\n",
      " [ 93 344]]\n",
      "\n",
      "Correct Predictions: 3709\n",
      "Incorrect Predictions: 827\n",
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "4531    0\n",
      "4532    1\n",
      "4533    1\n",
      "4534    1\n",
      "4535    0\n",
      "Name: PreDM, Length: 4536, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## confusion matrix using XGBoost model\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, fold_num):\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Confusion Matrix - Fold {fold_num}\")\n",
    "    #plt.savefig('final_visualizations/confusion_matrix.png')\n",
    "    #plt.show()\n",
    "\n",
    "# XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(eval_metric='logloss', random_state=42, alpha=0.5)\n",
    "\n",
    "fold_cm = []\n",
    "total_samples = 0\n",
    "all_predictions = np.zeros(len(y))  # Start with zeros for all predictions\n",
    "\n",
    "for fold_num, (train_index, test_index) in enumerate(kf.split(X, y), start=1):\n",
    "    X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    xgb_model.fit(X_train_cv, y_train_cv)\n",
    "    y_pred_cv = xgb_model.predict(X_test_cv)\n",
    "\n",
    "    all_predictions[test_index] = y_pred_cv\n",
    "\n",
    "    #print(y_pred_cv)\n",
    "\n",
    "    cm = confusion_matrix(y_test_cv, y_pred_cv)\n",
    "    fold_cm.append(cm)\n",
    "\n",
    "    print(f\"Confusion Matrix for Fold {fold_num}: \\n{cm}\\n\")\n",
    "\n",
    "     # Plot confusion matrix after each fold\n",
    "    #plot_confusion_matrix(cm, fold_num)\n",
    "\n",
    "# Compare predictions to actual values and label them as correct (1) or incorrect (0)\n",
    "correct_predictions = (all_predictions == y).astype(int)\n",
    "\n",
    "labeled_selected_features[\"Prediction_Correct\"] = correct_predictions\n",
    "    \n",
    "labeled_selected_features.to_csv(\"selected_features_labeled_final_with_predictions.csv\", sep='\\t', index=False)\n",
    "\n",
    "# Count of correct predictions (where Prediction_Correct == 1)\n",
    "correct_count = labeled_selected_features[\"Prediction_Correct\"].sum()\n",
    "\n",
    "# Count of incorrect predictions (where Prediction_Correct == 0)\n",
    "incorrect_count = len(labeled_selected_features) - correct_count\n",
    "\n",
    "# Print the results\n",
    "print(f\"Correct Predictions: {correct_count}\")\n",
    "print(f\"Incorrect Predictions: {incorrect_count}\")\n",
    "\n",
    "print(correct_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of correct and wrong values\n",
    "correct = labeled_selected_features[labeled_selected_features['Prediction_Correct']==1]\n",
    "wrong = labeled_selected_features[labeled_selected_features['Prediction_Correct']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_desc = correct.describe()\n",
    "wrong_desc = wrong.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between correct and wrong predictions summary statistics:\n",
      "              SEQN       BPQ020       DIQ010      DIQ190A      DIQ190B  \\\n",
      "count  2882.000000  2882.000000  2882.000000  2882.000000  2882.000000   \n",
      "mean     -0.341995    -0.068685    -0.049054    -0.120991    -0.090017   \n",
      "std     -79.352676    -0.162708    -0.006979     0.132354     0.073091   \n",
      "min     -21.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%    -122.000000     0.000000     0.000000     0.000000    -1.000000   \n",
      "50%     229.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%    -163.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max      -7.000000    -7.000000    -6.000000     7.000000     7.000000   \n",
      "\n",
      "            PAQ180     PADACTIV     PADDURAT      SLD010H     RIAGENDR  \\\n",
      "count  2882.000000  2882.000000  2882.000000  2882.000000  2882.000000   \n",
      "mean      0.124086    -0.065913    -1.357260    -0.145969    -0.013044   \n",
      "std       0.065894    -0.454813    -2.193697    -0.939445    -0.000674   \n",
      "min       0.000000     0.000000     0.000000    -2.000000     0.000000   \n",
      "25%       0.000000     0.000000    -2.500000     0.000000     0.000000   \n",
      "50%       0.000000    -2.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "\n",
      "          RIDAGEMN        PreDM  Prediction_Correct  \n",
      "count  2882.000000  2882.000000              2882.0  \n",
      "mean      3.005135    -0.044834                 1.0  \n",
      "std       4.970000     0.001064                 0.0  \n",
      "min       0.000000     0.000000                 1.0  \n",
      "25%     -11.000000     0.000000                 1.0  \n",
      "50%       2.000000    -1.000000                 1.0  \n",
      "75%      28.000000     0.000000                 1.0  \n",
      "max       0.000000     0.000000                 1.0  \n"
     ]
    }
   ],
   "source": [
    "difference = correct_desc - wrong_desc\n",
    "\n",
    "# Print the difference\n",
    "#print(\"Difference between correct and wrong predictions summary statistics:\")\n",
    "#print(difference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
