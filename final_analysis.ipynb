{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "selected_features_labeled  = pd.read_csv(\"selected_features.csv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>BPQ020</th>\n",
       "      <th>DIQ010</th>\n",
       "      <th>DID040</th>\n",
       "      <th>DIQ220</th>\n",
       "      <th>DIQ190A</th>\n",
       "      <th>DIQ190B</th>\n",
       "      <th>DIQ230</th>\n",
       "      <th>DID260</th>\n",
       "      <th>DIQ280</th>\n",
       "      <th>...</th>\n",
       "      <th>DIQ300D</th>\n",
       "      <th>PAQ180</th>\n",
       "      <th>PADACTIV</th>\n",
       "      <th>PADDURAT</th>\n",
       "      <th>SLD010H</th>\n",
       "      <th>LBXAPB</th>\n",
       "      <th>LBDINSI</th>\n",
       "      <th>LBXGH</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEMN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>6.9</td>\n",
       "      <td>...</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>53.94</td>\n",
       "      <td>7.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>6.9</td>\n",
       "      <td>...</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>53.94</td>\n",
       "      <td>7.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>111.00</td>\n",
       "      <td>87.06</td>\n",
       "      <td>5.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92.33</td>\n",
       "      <td>66.89</td>\n",
       "      <td>5.31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92.33</td>\n",
       "      <td>66.89</td>\n",
       "      <td>5.31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>41462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>92.00</td>\n",
       "      <td>24.36</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>41462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>92.00</td>\n",
       "      <td>24.36</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>41462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>92.00</td>\n",
       "      <td>24.36</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>41465.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>342.54</td>\n",
       "      <td>5.60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>41472.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>91.00</td>\n",
       "      <td>98.04</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4963 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SEQN  BPQ020  DIQ010  DID040  DIQ220  DIQ190A  DIQ190B  DIQ230  \\\n",
       "0     31132.0     1.0     1.0    63.0     0.0      1.0        1     1.0   \n",
       "1     31132.0     1.0     1.0    63.0     0.0      1.0        1     1.0   \n",
       "2     31134.0     1.0     2.0     0.0     0.0      1.0        1     0.0   \n",
       "3     31139.0     1.0     2.0     0.0     0.0      1.0        1     0.0   \n",
       "4     31139.0     1.0     2.0     0.0     0.0      1.0        1     0.0   \n",
       "...       ...     ...     ...     ...     ...      ...      ...     ...   \n",
       "4958  41462.0     2.0     2.0     0.0     0.0      2.0        2     0.0   \n",
       "4959  41462.0     2.0     2.0     0.0     0.0      2.0        2     0.0   \n",
       "4960  41462.0     2.0     2.0     0.0     0.0      2.0        2     0.0   \n",
       "4961  41465.0     2.0     2.0     0.0     0.0      1.0        1     0.0   \n",
       "4962  41472.0     1.0     2.0     0.0     0.0      2.0        1     0.0   \n",
       "\n",
       "      DID260  DIQ280  ...  DIQ300D  PAQ180  PADACTIV  PADDURAT  SLD010H  \\\n",
       "0         55     6.9  ...     2.53     2.0      42.0      40.0      7.0   \n",
       "1         55     6.9  ...     2.53     2.0      19.0     240.0      7.0   \n",
       "2          0     0.0  ...     0.00     3.0      42.0      30.0      7.0   \n",
       "3          0     0.0  ...     0.00     2.0      10.0      15.0      6.0   \n",
       "4          0     0.0  ...     0.00     2.0      40.0      30.0      6.0   \n",
       "...      ...     ...  ...      ...     ...       ...       ...      ...   \n",
       "4958       0     0.0  ...     0.00     3.0      42.0      30.0      8.0   \n",
       "4959       0     0.0  ...     0.00     3.0      20.0     120.0      8.0   \n",
       "4960       0     0.0  ...     0.00     3.0      29.0      10.0      8.0   \n",
       "4961       0     0.0  ...     0.00     1.0      42.0      30.0      6.0   \n",
       "4962       0     0.0  ...     0.00     2.0      29.0      20.0      8.0   \n",
       "\n",
       "      LBXAPB  LBDINSI  LBXGH  RIAGENDR  RIDAGEMN  \n",
       "0      75.00    53.94   7.10       1.0       842  \n",
       "1      75.00    53.94   7.10       1.0       842  \n",
       "2     111.00    87.06   5.90       1.0       882  \n",
       "3      92.33    66.89   5.31       2.0       217  \n",
       "4      92.33    66.89   5.31       2.0       217  \n",
       "...      ...      ...    ...       ...       ...  \n",
       "4958   92.00    24.36   5.10       1.0       678  \n",
       "4959   92.00    24.36   5.10       1.0       678  \n",
       "4960   92.00    24.36   5.10       1.0       678  \n",
       "4961   84.00   342.54   5.60       2.0       222  \n",
       "4962   91.00    98.04   4.80       1.0       410  \n",
       "\n",
       "[4963 rows x 21 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values:  0\n",
      "Missing values per column: \n",
      " SEQN        0\n",
      "BPQ020      0\n",
      "DIQ010      0\n",
      "DID040      0\n",
      "DIQ220      0\n",
      "DIQ190A     0\n",
      "DIQ190B     0\n",
      "DIQ230      0\n",
      "DID260      0\n",
      "DIQ280      0\n",
      "DIQ300S     0\n",
      "DIQ300D     0\n",
      "PAQ180      0\n",
      "PADACTIV    0\n",
      "PADDURAT    0\n",
      "SLD010H     0\n",
      "LBXAPB      0\n",
      "LBDINSI     0\n",
      "LBXGH       0\n",
      "RIAGENDR    0\n",
      "RIDAGEMN    0\n",
      "dtype: int64\n",
      "Columns with all zero values:  SEQN           0\n",
      "BPQ020         0\n",
      "DIQ010         0\n",
      "DID040      4733\n",
      "DIQ220      4914\n",
      "DIQ190A        0\n",
      "DIQ190B        0\n",
      "DIQ230      4733\n",
      "DID260      4765\n",
      "DIQ280      4785\n",
      "DIQ300S     4733\n",
      "DIQ300D     4733\n",
      "PAQ180         0\n",
      "PADACTIV       0\n",
      "PADDURAT       3\n",
      "SLD010H        0\n",
      "LBXAPB       349\n",
      "LBDINSI      372\n",
      "LBXGH        329\n",
      "RIAGENDR       0\n",
      "RIDAGEMN      32\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "selected_features_labeled.value_counts()\n",
    "#zero_value_cols = selected_features_labeled.columns[(selected_features_labeled == 0).all()]\n",
    "#zero_only_cols = selected_features_labeled.columns[(selected_features_labeled.eq(0)).all()]\n",
    "zero_counts = (selected_features_labeled == 0).sum()\n",
    "\n",
    "print(\"Total missing values: \", selected_features_labeled.isnull().sum().sum())\n",
    "print(\"Missing values per column: \\n\", selected_features_labeled.isnull().sum())\n",
    "print(\"Columns with all zero values: \", zero_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros in the selected features: SEQN        0\n",
      "BPQ020      0\n",
      "DIQ010      0\n",
      "DIQ190A     0\n",
      "DIQ190B     0\n",
      "PAQ180      0\n",
      "PADACTIV    0\n",
      "PADDURAT    0\n",
      "SLD010H     0\n",
      "LBXAPB      0\n",
      "LBDINSI     0\n",
      "LBXGH       0\n",
      "RIAGENDR    0\n",
      "RIDAGEMN    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "zero_counts = (selected_features_labeled == 0).sum()\n",
    "print(\"Number of zeros in the selected features:\", zero_counts)\n",
    "\n",
    "#drop columns\n",
    "selected_features_labeled = selected_features_labeled.drop(columns=[\n",
    "    'DID040', 'DIQ220', 'DIQ230', 'DID260', 'DIQ280', 'DIQ300S', 'DIQ300D'\n",
    "], errors='ignore')\n",
    "\n",
    "#drop rows\n",
    "#selected_features_labeled = selected_features_labeled.drop(index=['LBXAPB', 'LBDINSI', 'LBXGH', 'PADDURAT', 'RIDAGEMN'], errors='ignore')\n",
    "\n",
    "cols_to_check = ['LBXAPB', 'LBDINSI', 'LBXGH', 'PADDURAT', 'RIDAGEMN']\n",
    "\n",
    "# Drop rows where any of the specified columns contain a zero\n",
    "selected_features_labeled = selected_features_labeled[(selected_features_labeled[cols_to_check] != 0).all(axis=1)]\n",
    "\n",
    "#print(\"Remaining columns:\", selected_features_labeled.columns.tolist().count())\n",
    "#print(\"Remaining rows:\", selected_features_labeled.index.tolist().count())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_labeled\n",
    "\n",
    "## save cleaned data to a CSV file\n",
    "def save_cleaned_data(df, data_path=\"selected_features_final.csv\"):\n",
    "    if not df.empty:\n",
    "        df.to_csv(data_path, sep='\\t', index=False)\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "save_cleaned_data(selected_features_labeled, data_path=\"selected_features_final.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>BPQ020</th>\n",
       "      <th>DIQ010</th>\n",
       "      <th>DIQ190A</th>\n",
       "      <th>DIQ190B</th>\n",
       "      <th>PAQ180</th>\n",
       "      <th>PADACTIV</th>\n",
       "      <th>PADDURAT</th>\n",
       "      <th>SLD010H</th>\n",
       "      <th>LBXAPB</th>\n",
       "      <th>LBDINSI</th>\n",
       "      <th>LBXGH</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEMN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>75</td>\n",
       "      <td>53.94</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>75</td>\n",
       "      <td>53.94</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>111</td>\n",
       "      <td>87.06</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31148.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>47</td>\n",
       "      <td>62.76</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31150.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>43.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>75</td>\n",
       "      <td>23.46</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>41462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>92</td>\n",
       "      <td>24.36</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>41462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>92</td>\n",
       "      <td>24.36</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>41462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>92</td>\n",
       "      <td>24.36</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>41465.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>84</td>\n",
       "      <td>342.54</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>41472.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>91</td>\n",
       "      <td>98.04</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4536 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SEQN  BPQ020  DIQ010  DIQ190A  DIQ190B  PAQ180  PADACTIV  PADDURAT  \\\n",
       "0     31132.0     1.0     1.0      1.0        1       2      42.0      40.0   \n",
       "1     31132.0     1.0     1.0      1.0        1       2      19.0     240.0   \n",
       "2     31134.0     1.0     2.0      1.0        1       3      42.0      30.0   \n",
       "17    31148.0     2.0     2.0      2.0        2       2      23.0      60.0   \n",
       "18    31150.0     2.0     2.0      2.0        2       4      43.0      60.0   \n",
       "...       ...     ...     ...      ...      ...     ...       ...       ...   \n",
       "4958  41462.0     2.0     2.0      2.0        2       3      42.0      30.0   \n",
       "4959  41462.0     2.0     2.0      2.0        2       3      20.0     120.0   \n",
       "4960  41462.0     2.0     2.0      2.0        2       3      29.0      10.0   \n",
       "4961  41465.0     2.0     2.0      1.0        1       1      42.0      30.0   \n",
       "4962  41472.0     1.0     2.0      2.0        1       2      29.0      20.0   \n",
       "\n",
       "      SLD010H  LBXAPB  LBDINSI  LBXGH  RIAGENDR  RIDAGEMN  \n",
       "0         7.0      75    53.94    7.1       1.0       842  \n",
       "1         7.0      75    53.94    7.1       1.0       842  \n",
       "2         7.0     111    87.06    5.9       1.0       882  \n",
       "17        7.0      47    62.76    5.0       2.0       194  \n",
       "18        8.0      75    23.46    5.0       1.0       959  \n",
       "...       ...     ...      ...    ...       ...       ...  \n",
       "4958      8.0      92    24.36    5.1       1.0       678  \n",
       "4959      8.0      92    24.36    5.1       1.0       678  \n",
       "4960      8.0      92    24.36    5.1       1.0       678  \n",
       "4961      6.0      84   342.54    5.6       2.0       222  \n",
       "4962      8.0      91    98.04    4.8       1.0       410  \n",
       "\n",
       "[4536 rows x 14 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test line\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "## preDM filter\n",
    "def main():\n",
    "    combined_selected_features = pd.read_csv('selected_features_final.csv', sep='\\t')\n",
    "    preDM_criteria = (combined_selected_features['LBDINSI'] >= 100) | (combined_selected_features['LBXAPB'] >= 110) | (combined_selected_features['LBXGH'] >= 5.5)\n",
    "\n",
    "    preDMCondFilter(combined_selected_features, preDM_criteria)\n",
    "    print('test line')\n",
    "\n",
    "def preDMCondFilter(combined_selected_features, preDM_criteria):\n",
    "    \n",
    "    #combined_selected_features.columns = combined_selected_features.columns.str.strip()\n",
    "\n",
    "    combined_selected_features['PreDM'] = preDM_criteria.astype(int)\n",
    "\n",
    "    combined_selected_features.to_csv('selected_features_labeled_final.csv', sep='\\t', index=False)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selected_features_labeled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mselected_features_labeled\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'selected_features_labeled' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def prepareData():\n",
    "    labeled_selected_features = pd.read_csv('../selected_features_labeled.csv', sep='\\t', header=0)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = encode_and_split(labeled_selected_features)\n",
    "\n",
    "    X_train_scaled, X_test_scaled = scaleFeatures(X_train, X_test)\n",
    " \n",
    "    #X_resampled, y_resampled = handle_class_imbalance(X_train_scaled, y_train)\n",
    "\n",
    "    return X_train, X_test, X_test_scaled, y_test\n",
    "\n",
    "def encode_and_split(labeled_selected_features):\n",
    "\n",
    "    #X = labeled_selected_features[['BPQ020', 'PADDURAT', 'SLD010H', 'RIAGENDR', 'LBXAPB', 'LBDINSI', 'LBXGH']]\n",
    "    X = labeled_selected_features[['BPQ020', 'PADDURAT',  'SLD010H']]\n",
    "    Y = labeled_selected_features[\"PreDM\"].copy()\n",
    "   \n",
    "    X = X.loc[Y.index]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, train_size=0.7, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def scaleFeatures(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# oversample the minority class using SMOTE\n",
    "# avoid overfitting\n",
    "# improves performance on imbalanced datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m      5\u001b[39m     X_train, X_test, X_test_scaled, y_test = prepareData()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     accuracy = \u001b[43mtrain_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mtrain_evaluate_model\u001b[39m\u001b[34m(X_train, X_test, X_test_scaled, y_test)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_evaluate_model\u001b[39m(X_train, X_test, X_test_scaled, y_test):\n\u001b[32m     10\u001b[39m     dt_model = DecisionTreeClassifier(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[43mdt_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     y_pred = dt_model.predict(X_test_scaled)\n\u001b[32m     15\u001b[39m     accuracy = accuracy_score(y_test, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Bhavana\\College\\FURI_Project\\FURI_Research-Project\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Bhavana\\College\\FURI_Project\\FURI_Research-Project\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1024\u001b[39m, in \u001b[36mDecisionTreeClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, check_input=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    995\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[32m    996\u001b[39m \n\u001b[32m    997\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1021\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m   1022\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Bhavana\\College\\FURI_Project\\FURI_Research-Project\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:252\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    248\u001b[39m check_X_params = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    249\u001b[39m     dtype=DTYPE, accept_sparse=\u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m, ensure_all_finite=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    250\u001b[39m )\n\u001b[32m    251\u001b[39m check_y_params = \u001b[38;5;28mdict\u001b[39m(ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_separately\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m missing_values_in_feature_mask = (\n\u001b[32m    257\u001b[39m     \u001b[38;5;28mself\u001b[39m._compute_missing_values_in_feature_mask(X)\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Bhavana\\College\\FURI_Project\\FURI_Research-Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2959\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2957\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mestimator\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_y_params:\n\u001b[32m   2958\u001b[39m         check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m-> \u001b[39m\u001b[32m2959\u001b[39m     y = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2960\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2961\u001b[39m     X, y = check_X_y(X, y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Bhavana\\College\\FURI_Project\\FURI_Research-Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1107\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1116\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Bhavana\\College\\FURI_Project\\FURI_Research-Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Bhavana\\College\\FURI_Project\\FURI_Research-Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def main():\n",
    "    X_train, X_test, X_test_scaled, y_test = prepareData()\n",
    "    accuracy = train_evaluate_model(X_train, X_test, X_test_scaled, y_test)\n",
    "    return accuracy\n",
    "\n",
    "def train_evaluate_model(X_train, X_test, X_test_scaled, y_test):\n",
    "    dt_model = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model.fit(X_train, X_test)\n",
    "\n",
    "    y_pred = dt_model.predict(X_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Decision Tree Accuracy: {accuracy:.2f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— Getting requirements to build wheel did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Ã— Getting requirements to build wheel did not run successfully.\n",
      "â”‚ exit code: 1\n",
      "â•°â”€> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\bhavana\\college\\furi_project\\furi_research-project\\.venv\\lib\\site-packages (from scikit-learn) (2.2.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.1 MB 2.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 2.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.4/11.1 MB 2.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.4/11.1 MB 2.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.9/11.1 MB 2.8 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.7/11.1 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.2/11.1 MB 2.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.0/11.1 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.1/11.1 MB 2.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.4/11.1 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.9/11.1 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.7/11.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.1 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 2.7 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "   ---------------------------------------- 0.0/40.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/40.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/40.9 MB 1.9 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 1.3/40.9 MB 2.0 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 1.8/40.9 MB 2.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 2.4/40.9 MB 2.2 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 2.9/40.9 MB 2.3 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 3.4/40.9 MB 2.3 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 3.9/40.9 MB 2.4 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 4.5/40.9 MB 2.3 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 4.7/40.9 MB 2.2 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 5.0/40.9 MB 2.2 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 5.5/40.9 MB 2.1 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 5.8/40.9 MB 2.1 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 6.0/40.9 MB 2.1 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 6.3/40.9 MB 2.0 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 7.1/40.9 MB 2.0 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 7.6/40.9 MB 2.1 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 7.9/40.9 MB 2.0 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 8.4/40.9 MB 2.1 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 8.9/40.9 MB 2.1 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 9.4/40.9 MB 2.1 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 10.0/40.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 10.5/40.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 11.0/40.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 11.5/40.9 MB 2.1 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 11.8/40.9 MB 2.1 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 12.3/40.9 MB 2.1 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 12.6/40.9 MB 2.1 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 13.4/40.9 MB 2.1 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 13.9/40.9 MB 2.1 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 14.4/40.9 MB 2.2 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 14.9/40.9 MB 2.2 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 15.5/40.9 MB 2.2 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 16.0/40.9 MB 2.2 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 16.8/40.9 MB 2.2 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 17.3/40.9 MB 2.2 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 17.8/40.9 MB 2.2 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 18.4/40.9 MB 2.3 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 19.1/40.9 MB 2.3 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 19.7/40.9 MB 2.3 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 20.4/40.9 MB 2.3 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 21.0/40.9 MB 2.3 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 21.8/40.9 MB 2.4 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 22.5/40.9 MB 2.4 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 22.8/40.9 MB 2.4 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 23.6/40.9 MB 2.4 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 24.1/40.9 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 24.9/40.9 MB 2.4 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 25.4/40.9 MB 2.4 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 26.2/40.9 MB 2.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 27.0/40.9 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 27.5/40.9 MB 2.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 28.0/40.9 MB 2.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 28.6/40.9 MB 2.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 29.4/40.9 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 29.9/40.9 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 30.7/40.9 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 31.2/40.9 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 31.7/40.9 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 32.0/40.9 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 32.5/40.9 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 33.0/40.9 MB 2.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 33.8/40.9 MB 2.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 34.3/40.9 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 35.1/40.9 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 35.9/40.9 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 36.4/40.9 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 37.0/40.9 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 37.7/40.9 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 38.3/40.9 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 38.8/40.9 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.1/40.9 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.6/40.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.1/40.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.4/40.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 40.9/40.9 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
